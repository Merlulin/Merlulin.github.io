# 行人属性识别

## 基于解耦表征学习的行人属性识别

> Learning Disentangled Attribute Representations for Robust Pedestrian Attribute Recognition

### 研究现状：

    现有的行人属性识别方法，通常采用学习一个共享的行人图像特征来对多个属性进行分类。
    但是这种机制会导致在模型推理阶段的鲁棒性和置信度降低。
    现有的方法可分为如下几类：
    1. 提取一个共享的全局特征来对所有属性进行分类
        (HydraPlusNet、MsVAA、VAC、JLAC)
    2. 根据属性的空间分布将属性分成若干组，采用一组特征对同一组中的多个属性进行分类
        （RC&RA、VSGR）
    3. 试图为每个属性提取一个特定的特征

### 采用共享的全局特征为什么存在问题？
>[!note]
我们假设对于第j个属性，第i个样本，该样本在经过最后的分类层之后输出结果设为$logits_{i,j}$，此时第i个样本预测为第j个属性的概率为$p_{i,j}=\sigma(logits_{i,j})$，$\sigma$就是Sigmoid函数。我们默认设定预测的阈值$p_t=0.5$，则有$\hat{y}_{i, j}=\left\{\begin{array}{ll}
1, & p_{i, j}>=p_{t} \\
0, & p_{i, j}<p_{t}
\end{array},\right.$
>
>继续假定$logits_{i,j}=w^T_jf_i=|w_j|*|f_i|·cos\theta$，其中$w_j$表示第j个属性的权重向量，$f_i$则是共享的$x_i$样本特征向量。<br> 将上述式子进行整合，可以得到$\hat{y}_{i, j}=\left\{\begin{array}{ll}
1, & 0^{\circ}<=\theta<=90^{\circ} \\
0, & 90^{\circ}<\theta<180^{\circ}
\end{array} \right.$ <br>此时可以看出我们最后的预测结果只和$cos\theta$相关，而$\theta$就是特征向量$f$和属性分类权重向量$w$的夹角。<br> 因此，对于一个目标属性，一个经过良好训练的模型应该使正样本特征与对应的分类器权重之间的角度尽可能小，甚至接近0 °，这意味着高置信度的预测。<br>但是在实验中观测到，属性分类的权重向量大多是正交的，而从直观上就可以发现两者既然正交，那么必然不可能使得共享的特征向量和多个属性权重向量的角度都接近于0°。然而角度越接近于0°时意味着模型的置信度越高，所以需要进一步去推测理论上最佳的角度是多少？<br> **答：<br>**
**在二分类属性情况下，最佳的共享特征向量应该位于两个分类器的中间，也就是到两个分类器距离相同，即与两个分类权重向量的角度$\theta=45°$；进一步推广到三分类属性情况下，最佳的$\theta=54.74$。**<br>**我们得出结论，最合适的样本特征$f_i$通过最小化二进制交叉熵损失实现了自身与多个分类器之间的距离的权衡。该属性使最佳角度随着属性数量的增加而收敛到90 °。具体而言，在现有数据集PA 100k、PETA和RAP上，属性θ分别为26、35、51，最佳角度分别为78,69°、80.27°、81.27°**。
><div align=center>
    <p>收敛曲线图：</p>
    <img src="Paper\Intensive\Pedestrian_attribute_recognition\image.png" style="width: 30%; height: 30%;">
></div>
>
>然而，训练阶段接近90°的最佳角度与我们的预期相去甚远。因此，微小的扰动可能会使测试集的特征越过决策边界，导致测试集的角度大于90°，并产生错误的预测。具体地说，学习到的特征容易受到行人姿势、光照和背景变化的影响，导致不正确的分类。因此，我们得出结论，通过OFMA机制学习的共享特征离分类器太远，这降低了模型在测试集上的稳健性。此外，值得注意的是，这一缺陷是由OFMA机制确定的，与具体方法无关。

>[!tip]
>什么，如果你问我怎么才能像文中说的计算出不同类别数情况下的最佳角度$\theta$。说实话，论文没说明我也不知道！

### 为了解决上述问题，本文提出了DAFL架构。
![Alt text](image-1.png)
>[!tip]
>DAFL架构主要由连续的SSCA模块和GAM模块组成

#### SSCA模块
> 该模块的提出用于为每个属性定位在空间中的区域，并将区域特征汇聚成一个属性特征

<div align=center>
    <img src="Paper\Intensive\Pedestrian_attribute_recognition\image-2.png" style="width: 50%; height: 50%;">
</div>

对于第s个SSCA模块（因为是级联的），其输入包括两部分：1. 语义查询$Q^S\in R^{C \times M}$(对于第一个SSCA有点类似于attention中的Q，是一个学习出来的向量，对于后续的SSCA模块，其Q就是上一个SSCA的输入特征图)；2. 特征图$\mathcal{F} \in R^{C \times H \times W}$
作者在SSCA模块中进一步参考Transformer的MHA，对于SSCA模块内部的计算同样仿照多头注意力机制进行设计。SSCA模块的输出一个查询注意力图$A \in R^{M \times H \times W}$ 和 属性特征图$F^s \in R^{C \times M}$，其中$A=Softmax(\frac{\theta (Q)^T \phi (\mathcal{F})}{\sqrt(C)})$ ，$F^s = A\psi(\mathcal{F})^T$。(公式中的$\theta(Q),\phi (\mathcal{F})和 \psi(\mathcal{F}) $实际就是两个线性映射，和Transformer的QKV一个道理)
>[!note]除了第一个SSCA模块的$Q^0$是随机初始化的，后续的SSCA模块的$Q^s$实际是前一个SSCA模块的输出$F^{s-1}$
#### GAM模块
> 该模块的提出主要是解决部分属性存在样本量小，无法精准的定位到空间区域，导致得到的特征注意力分布效果较差，所以提出GAM使用一组在空间分布上近似的属性组来监督少样本的空间区域。

具体步骤分两步:1. 将所有属性按照空间分布认为划分为若干组G；2. 使用GAM（组注意力合并）机制将满足要求的查询注意力图合并成一个组注意力。
>[!note]具体如何汇集，先给出公式：$G_k^a=\frac{1}{|\mathcal{G}_k|}\sum_{m \in \mathcal{G}_k}^{} \frac{1}{|\mathcal{R}|} \sum_{i=1}^{b_t}\mathcal{1}_{{\mathcal\{R\}}}A_{i,m}$<br>
其中$A_{i,m}$表示第i个样本对于第m个属性的注意力图，$\mathcal{1}_{{\mathcal\{R\}}}$即为指示器，$\mathcal{R}= \{\sigma(logits_{i,m}) > \tau, y_{i,m} = 1\}$，也就是当该样本指定为该类时收集其注意力图，对每一个Batch进行注意力图汇集（就是累加后求平均）,同理对第K组内的所有属性进行注意力图汇集，将同组所有属性的注意力图汇集后再求一个组平均得到的结果就是该组的注意力图。同时对于每个batch计算得到的组注意力，我们采用momentum的思想进行平滑记忆$G_k^m \longleftarrow (1-\alpha) \times G_k^m + \alpha \times G_k^a$，可以缓解有限批量和随机抽样造成的一些扰动，使得组注意力在不同Batch之间保持可靠和一致性。<br> 紧接着本文进一步将汇集得到的组注意力$G_k^m$作为伪标签，监督组内注意力不够精准的查询注意力图（也就是样本量较少的属性），继而本文提出了组一致性损失的概念来作为损失函数的一部分：$L_{group}=\frac{1}{b_t}||\sum_{i=1}^{b_t}\sum_{k=1}^{K}\sum_{m\in G_k}G_k^m-A_{i,m}||_2,||$，使得模型训练的过程中可以不断纠正少样本属性的查询注意力图。

#### triple loss
> 现在就是说虽然通过级联的SSCA和GAM可以获得有空间区别定位的属性特征，但是在本文的实验中发现正样本之间的距离大于正负样本之间的距离（分布不均），会破坏模型的鲁棒性，所以本文又引入了三重损失来解决这个问题，消除正例的紧凑型和正负样例之间的差异。

对于每个属性，我们会从当前批次中选择一个正样例$a_m^p$，一个最难抉择的正样例$f_m^p$和一个最难抉择的负样例$f_m^n$,构成一个正三元组$(a_m^p,f_m^p,f_m^n)$, 正三元组的损失计算公式：$L_{pos,m}=\sum_{j\in N_m^p}max(0,D(a_j^p,f_j^p)-D(a_j^p,f_j^n))$。
>其中N_m^p是第m个属性正例的个数，D是计算距离函数
>该损失函数的目的是：最小化$a_m^p 和 f_m^p $之间的距离，并最大化$a_m^p 和 f_m^n $之间的距离

同理构建一个负三元组$(a_m^n,f_m^n,f_m^p)$，负三元组的损失计算公式：$L_{neg,m}=\sum_{j\in N_m^n}max(0,D(a_j^n,f_j^n)-D(a_j^n,f_j^p))$

>[!tip]还没结束哦！因为既然存在正负样本数目过小的情况，那么构建三元组同样会遇到这个问题：一个批次中的正例或负例太少，无法构建有效的三元组，所以采用了MOCO在2020年提出的Queue Dictionary机制动态存储每个属性的正例和负例，除了当前batch，还会从动态队列中随机抽取再构建两个额外的正负三元组计算损失。